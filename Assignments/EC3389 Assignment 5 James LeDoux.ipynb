{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 5 - Programming portion**\n",
    "**EC3389 - James LeDoux**\n",
    "\n",
    "My approach as follows:\n",
    "\n",
    "I began by running LogisticRegressionCV to eliminate features. At its optimal level, this left me with 37 non-zero features. These 37 features are my answer to question one.  I then run 5-fold cross validation on a logistic regression model. My answer to question two (estimating the coefficients) is the set of coefficients given by the best model found during this process. My answer to question three was my cross-validation MSE, also determined during this process. To extend this answer, I also include a confusion matrix at the end of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation, datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X2991</th>\n",
       "      <th>X2992</th>\n",
       "      <th>X2993</th>\n",
       "      <th>X2994</th>\n",
       "      <th>X2995</th>\n",
       "      <th>X2996</th>\n",
       "      <th>X2997</th>\n",
       "      <th>X2998</th>\n",
       "      <th>X2999</th>\n",
       "      <th>X3000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.589817</td>\n",
       "      <td>-2.186313</td>\n",
       "      <td>-0.918072</td>\n",
       "      <td>0.994456</td>\n",
       "      <td>-1.643339</td>\n",
       "      <td>0.562897</td>\n",
       "      <td>0.871649</td>\n",
       "      <td>1.645830</td>\n",
       "      <td>-2.246300</td>\n",
       "      <td>0.293383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316473</td>\n",
       "      <td>1.390242</td>\n",
       "      <td>-3.113475</td>\n",
       "      <td>-0.856392</td>\n",
       "      <td>4.717735</td>\n",
       "      <td>3.271560</td>\n",
       "      <td>-3.842866</td>\n",
       "      <td>1.951035</td>\n",
       "      <td>-3.268676</td>\n",
       "      <td>-3.486528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.932005</td>\n",
       "      <td>3.409547</td>\n",
       "      <td>-4.068428</td>\n",
       "      <td>-0.653186</td>\n",
       "      <td>-2.209341</td>\n",
       "      <td>4.181775</td>\n",
       "      <td>-0.386069</td>\n",
       "      <td>-4.761591</td>\n",
       "      <td>-0.402478</td>\n",
       "      <td>4.100881</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.431568</td>\n",
       "      <td>-4.795004</td>\n",
       "      <td>4.948272</td>\n",
       "      <td>-4.747840</td>\n",
       "      <td>4.994316</td>\n",
       "      <td>-1.031691</td>\n",
       "      <td>2.470805</td>\n",
       "      <td>1.708033</td>\n",
       "      <td>2.322733</td>\n",
       "      <td>4.224387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.437788</td>\n",
       "      <td>-3.771317</td>\n",
       "      <td>-4.990487</td>\n",
       "      <td>0.477881</td>\n",
       "      <td>-0.137070</td>\n",
       "      <td>-1.591236</td>\n",
       "      <td>-4.346859</td>\n",
       "      <td>-1.721320</td>\n",
       "      <td>4.796643</td>\n",
       "      <td>-2.855409</td>\n",
       "      <td>...</td>\n",
       "      <td>3.462669</td>\n",
       "      <td>4.386071</td>\n",
       "      <td>2.125671</td>\n",
       "      <td>-2.330933</td>\n",
       "      <td>-2.959368</td>\n",
       "      <td>-4.888772</td>\n",
       "      <td>4.643801</td>\n",
       "      <td>-1.187435</td>\n",
       "      <td>-3.244609</td>\n",
       "      <td>-4.497003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.949226</td>\n",
       "      <td>-4.555874</td>\n",
       "      <td>-0.704534</td>\n",
       "      <td>3.862392</td>\n",
       "      <td>-0.821387</td>\n",
       "      <td>1.230358</td>\n",
       "      <td>3.851150</td>\n",
       "      <td>-1.610159</td>\n",
       "      <td>-2.463466</td>\n",
       "      <td>-3.492688</td>\n",
       "      <td>...</td>\n",
       "      <td>2.383281</td>\n",
       "      <td>-1.757180</td>\n",
       "      <td>-4.993467</td>\n",
       "      <td>-3.424699</td>\n",
       "      <td>-0.581444</td>\n",
       "      <td>-1.865997</td>\n",
       "      <td>-4.177863</td>\n",
       "      <td>-4.196769</td>\n",
       "      <td>0.781339</td>\n",
       "      <td>-2.883281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.512552</td>\n",
       "      <td>1.290331</td>\n",
       "      <td>0.383730</td>\n",
       "      <td>-1.057689</td>\n",
       "      <td>1.835562</td>\n",
       "      <td>2.965427</td>\n",
       "      <td>-3.994274</td>\n",
       "      <td>-2.195604</td>\n",
       "      <td>4.841798</td>\n",
       "      <td>0.620592</td>\n",
       "      <td>...</td>\n",
       "      <td>4.740132</td>\n",
       "      <td>-2.491019</td>\n",
       "      <td>-4.629763</td>\n",
       "      <td>4.283172</td>\n",
       "      <td>0.612778</td>\n",
       "      <td>4.668735</td>\n",
       "      <td>1.077373</td>\n",
       "      <td>0.060312</td>\n",
       "      <td>-2.878469</td>\n",
       "      <td>2.312747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0 -4.589817 -2.186313 -0.918072  0.994456 -1.643339  0.562897  0.871649   \n",
       "1 -1.932005  3.409547 -4.068428 -0.653186 -2.209341  4.181775 -0.386069   \n",
       "2  0.437788 -3.771317 -4.990487  0.477881 -0.137070 -1.591236 -4.346859   \n",
       "3 -0.949226 -4.555874 -0.704534  3.862392 -0.821387  1.230358  3.851150   \n",
       "4  3.512552  1.290331  0.383730 -1.057689  1.835562  2.965427 -3.994274   \n",
       "\n",
       "         X8        X9       X10    ...        X2991     X2992     X2993  \\\n",
       "0  1.645830 -2.246300  0.293383    ...     1.316473  1.390242 -3.113475   \n",
       "1 -4.761591 -0.402478  4.100881    ...    -2.431568 -4.795004  4.948272   \n",
       "2 -1.721320  4.796643 -2.855409    ...     3.462669  4.386071  2.125671   \n",
       "3 -1.610159 -2.463466 -3.492688    ...     2.383281 -1.757180 -4.993467   \n",
       "4 -2.195604  4.841798  0.620592    ...     4.740132 -2.491019 -4.629763   \n",
       "\n",
       "      X2994     X2995     X2996     X2997     X2998     X2999     X3000  \n",
       "0 -0.856392  4.717735  3.271560 -3.842866  1.951035 -3.268676 -3.486528  \n",
       "1 -4.747840  4.994316 -1.031691  2.470805  1.708033  2.322733  4.224387  \n",
       "2 -2.330933 -2.959368 -4.888772  4.643801 -1.187435 -3.244609 -4.497003  \n",
       "3 -3.424699 -0.581444 -1.865997 -4.177863 -4.196769  0.781339 -2.883281  \n",
       "4  4.283172  0.612778  4.668735  1.077373  0.060312 -2.878469  2.312747  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data.csv\")\n",
    "y = data['Y']\n",
    "data = data.drop('Y', 1)\n",
    "data = data.drop('Unnamed: 0', 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PART ONE: USING LOGISTIC-CV TO ELIMINATE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CVmodel = LogisticRegressionCV(cv=10, penalty='l1', solver='liblinear').fit(data,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1225449 , -0.01734448, -0.02950021, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data frame has 3000 features\n",
      "kept 37 features after LassoCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesledoux/anaconda/envs/python3/lib/python3.5/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.246745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.241596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.240603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.240074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.233806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coeffs\n",
       "27  0.246745\n",
       "14  0.241596\n",
       "13  0.240603\n",
       "34  0.240074\n",
       "20  0.233806"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert coefficients to absolute values, only keep those that are > 0\n",
    "coefficientDf = pd.DataFrame()\n",
    "coefficientDf['coeffs'] = np.abs(CVmodel.coef_)[0]\n",
    "coefficientDf = coefficientDf.sort('coeffs', ascending=False)\n",
    "\n",
    "print(\"original data frame has \" + str(len(coefficientDf)) + \" features\")  \n",
    "indexList = coefficientDf[coefficientDf['coeffs'] >0].index.tolist() #indexes of non-zero coefficients\n",
    "print(\"kept \" + str(len(indexList)) + \" features after LassoCV\")\n",
    "coefficientDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-253bcac7dd80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#iterate through index list, dropping vars that are not in it\n",
    "for i in range(1,len(data.columns)+1):\n",
    "    if (i-1) in indexList:\n",
    "        pass\n",
    "    else:\n",
    "        name = \"X\" + str(i)\n",
    "        data = data.drop(name, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN ACCURACY SCORES DURING CROSS VALUDATION: [0.98599999999999999, 0.98899999999999999, 0.98999999999999999, 0.99099999999999999, 0.99099999999999999]\n",
      "coefficient estimates: \n",
      "X1: 1.37932625533\n",
      "X2: -0.40026780933\n",
      "X3: -0.433319381198\n",
      "X4: 2.20288571887\n",
      "X5: -1.3067224754\n",
      "X6: -2.25526521236\n",
      "X7: 1.83083506555\n",
      "X8: 2.23861326079\n",
      "X9: 0.395962552348\n",
      "X10: -0.409368601321\n",
      "X11: -0.853273958878\n",
      "X12: 0.946893250543\n",
      "X13: -0.929025504375\n",
      "X14: 2.31453495143\n",
      "X15: 2.2879621236\n",
      "X16: -1.37674954767\n",
      "X17: 0.449043180597\n",
      "X18: 1.34344390899\n",
      "X19: -2.2521312912\n",
      "X20: -0.436591997619\n",
      "X21: -2.24834427315\n",
      "X22: -0.473251771207\n",
      "X23: 0.856404053153\n",
      "X24: -1.79637712101\n",
      "X25: -0.460628025841\n",
      "X26: 2.212268048\n",
      "X27: 1.75195602193\n",
      "X28: -2.24862938569\n",
      "X29: 0.88846297215\n",
      "X30: -1.42754921101\n",
      "X31: 2.25149700315\n",
      "X32: 1.36625273876\n",
      "X33: 1.32317662679\n",
      "X34: -0.829798923922\n",
      "X35: 2.27032954057\n",
      "X36: -1.39197614717\n",
      "X37: 1.76440939113\n",
      "MSE scores:\n",
      "[0.013, 0.011, 0.011, 0.009, 0.007]\n",
      "Cross-Validated MSE: 0.0102\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Applying cross validation here. Taking the best score and model from the n folds I test. \n",
    "Keeping the best model's coefficients as my most accurate set. These coefficients are my \n",
    "answer to question number two. \n",
    "\n",
    "Also, I realize that taking MSE might be a bit overkill here since model.score() appears to be\n",
    "1-MSE. I could not verify that this was the case in the documentation, however, so better safe\n",
    "than sorry.\n",
    "\"\"\"\n",
    "model = LogisticRegression()\n",
    "\n",
    "mse_scores = []\n",
    "cv = KFold(n=data.shape[0] ,n_folds = 5)\n",
    "max_score = -float(\"inf\")   #score here is a mean accuracy, not mean error, so I maximize\n",
    "bestModel = None\n",
    "true_Y = None\n",
    "pred_Y = None\n",
    "for train, test in cv:\n",
    "    train_x = data.ix[train,:]\n",
    "    train_y = y.ix[train]\n",
    "    test_x = data.ix[test,:]\n",
    "    test_y = y.ix[test]\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "    preds = model.predict(test_x)\n",
    "    score = model.score(test_x, test_y)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        bestModel = model\n",
    "        true_Y = test_y    #keeping these values for the confusion matrix in the following cell\n",
    "        pred_Y = preds\n",
    "    sqError = (preds - test_y)**2\n",
    "    mse = np.mean(sqError)\n",
    "    mse_scores.append(mse)  \n",
    "\n",
    "print(\"MEAN ACCURACY SCORES DURING CROSS VALUDATION: \" + str(val_scores))\n",
    "\n",
    "coeffs = bestModel.coef_   \n",
    "cols = data.columns\n",
    "print(\"coefficient estimates: \")    #ANSWER TO QUESTION TWO \n",
    "for i in range(len(coeffs[0])):\n",
    "    variable = cols[i]\n",
    "    coeff = coeffs[0][i]\n",
    "    print(str(variable) + \": \" + str(coeff))\n",
    "\n",
    "print(\"MSE scores:\")\n",
    "print(mse_scores)\n",
    "CVmse = np.mean(mse_scores)\n",
    "print(\"Cross-Validated MSE: \" + str(CVmse))  #ANSWER TO PART 3 (MEASURE OF ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[489   1]\n",
      " [  6 504]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEpCAYAAACtNvjoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzcxy4gRsZpYTJ2Azs5z8D4ahro/wiIO0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c0c90b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ANOTHER WAY TO VIEW ACCURACY: CONFUSION MATRIX\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "c_mat = confusion_matrix(true_Y, pred_Y)\n",
    "plot_confusion_matrix(c_mat)\n",
    "print(\"confusion matrix: \")\n",
    "print(str(c_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
